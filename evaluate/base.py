import asyncio
import json
import logging
import re
import time
import uuid
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any, Optional, Tuple

from bohrium import Bohrium
from dotenv import load_dotenv, find_dotenv
from google.adk import Runner
from google.adk.agents import RunConfig
from google.adk.agents.run_config import StreamingMode
from google.adk.sessions import InMemorySessionService
from google.genai import types
from litellm import completion

from agents.matmaster_agent.agent import root_agent
from agents.matmaster_agent.constant import MATMASTER_AGENT_NAME
from agents.matmaster_agent.utils.event_utils import is_function_call
from evaluate.utils import load_dataset_json

logger = logging.getLogger(__name__)

load_dotenv(find_dotenv())


def evaluation_task(dataset_item):
    session_service = InMemorySessionService()
    runner = Runner(agent=root_agent, app_name=MATMASTER_AGENT_NAME, session_service=session_service)
    session = asyncio.run(session_service.create_session(
        app_name=MATMASTER_AGENT_NAME,
        user_id='evaluator',
        session_id=uuid.uuid4().hex
    ))

    expected_function_call = {}
    if dataset_item['input'].get('contents', None):
        user_query = dataset_item['input']['contents'][0]['parts'][0]['text']
    else:
        user_query = dataset_item['input']['parts'][0]['text']

    for part in dataset_item['expected_output']['content']['parts']:
        if part.get('function_call'):
            expected_function_call = {
                'function_name': part['function_call']['name'],
                'function_args': part['function_call']['args']
            }

    content = types.Content(role='user', parts=[types.Part(text=user_query)])

    events = []
    function_call = {}
    for event in runner.run(user_id=session.user_id, session_id=session.id, new_message=content):
        events.append(event)
        if is_function_call(event):
            function_call = {
                'function_name': event.content.parts[0].function_call.name,
                'function_args': event.content.parts[0].function_call.args
            }
            break

    output = events[-1].content.parts[0].text
    result = {
        'input': user_query,
        'output': output,
        'function_call': function_call,
        'expected_function_call': expected_function_call,
        'context': []
    }
    return result


def multi_turn_evaluation_task(dataset_item):
    session_service = InMemorySessionService()
    runner = Runner(agent=root_agent, app_name=MATMASTER_AGENT_NAME, session_service=session_service)
    session = asyncio.run(session_service.create_session(
        app_name=MATMASTER_AGENT_NAME,
        user_id='evaluator',
        session_id=uuid.uuid4().hex
    ))

    expected_function_call = {}
    turn_index = 2
    if dataset_item['input'].get('contents', None):
        user_query = ''
        for input_part in dataset_item['input']['contents'][:turn_index]:
            input_part_text = input_part['parts'][0]['text']
            input_part_role = input_part['role']
            user_query += f"For context: [{input_part_role}]\n{input_part_text}\n"
            user_query += '---------------------\n'
        user_query += dataset_item['input']['contents'][turn_index]['parts'][0]['text']
    else:
        user_query = dataset_item['input']['parts'][0]['text']
        if dataset_item['expected_output']['content']['parts'][0].get('function_call'):
            expected_function_call = {
                'function_name': dataset_item['expected_output']['content']['parts'][0]['function_call']['name'],
                'function_args': dataset_item['expected_output']['content']['parts'][0]['function_call']['args']
            }

    content = types.Content(role='user', parts=[types.Part(text=user_query)])

    events = []
    function_call = {}
    for event in runner.run(user_id=session.user_id, session_id=session.id, new_message=content):
        events.append(event)

    output = events[-1].content.parts[0].text
    result = {
        'input': user_query,
        'output': output,
        'function_call': function_call,
        'expected_function_call': expected_function_call,
        'context': []
    }
    return result


class ConversationState(Enum):
    """å¯¹è¯çŠ¶æ€æšä¸¾"""
    INITIAL = 'initial'
    IN_PROGRESS = 'in_progress'
    SATISFIED = 'satisfied'
    TIMEOUT = 'timeout'


@dataclass
class ConversationGoal:
    """å¯¹è¯ç›®æ ‡å®šä¹‰"""
    initial_question: str
    expected_outcomes: List[str]
    success_criteria: List[str]


class HumanSimulator:
    """
    ç®€åŒ–çš„äººç±»æ¨¡æ‹Ÿå™¨ - ç”¨äºå¤šè½®å¯¹è¯agentè¯„ä¼°

    åŠŸèƒ½ï¼š
    1. æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
    2. ç®¡ç†å¯¹è¯ç›®æ ‡
    3. ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å“åº”
    4. é™åˆ¶æœ€å¤š10è½®å¯¹è¯
    """

    def __init__(self, model: str = 'deepseek/deepseek-chat'):
        self.model = model
        self.conversation_history: List[Dict[str, Any]] = []
        self.current_state = ConversationState.INITIAL
        self.turn_count = 0
        self.start_time = None
        self.goal: Optional[ConversationGoal] = None

    def set_goal(self, goal: ConversationGoal):
        """è®¾ç½®å¯¹è¯ç›®æ ‡"""
        self.goal = goal
        self.current_state = ConversationState.INITIAL
        self.turn_count = 0
        self.start_time = time.time()
        logger.info(f"è®¾ç½®å¯¹è¯ç›®æ ‡: {goal.initial_question}")

    def get_initial_question(self) -> str:
        """è·å–åˆå§‹é—®é¢˜"""
        if not self.goal:
            raise ValueError('æœªè®¾ç½®å¯¹è¯ç›®æ ‡')
        return self.goal.initial_question

    def generate_response(self, agent_message: str) -> Tuple[str, bool]:
        """
        åŸºäºagentçš„å›å¤ç”Ÿæˆæ¨¡æ‹Ÿç”¨æˆ·çš„å“åº”

        Args:
            agent_message: agentçš„å›å¤å†…å®¹

        Returns:
            Tuple[str, bool]: (ç”¨æˆ·å“åº”, æ˜¯å¦ç»§ç»­å¯¹è¯)
        """
        if not self.goal:
            raise ValueError('æœªè®¾ç½®å¯¹è¯ç›®æ ‡')

        self.turn_count += 1
        self.conversation_history.append({
            'turn': self.turn_count,
            'agent': agent_message,
            'timestamp': time.time()
        })

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼ˆé™åˆ¶ä¸º10è½®ï¼‰
        if self.turn_count >= 10:
            self.current_state = ConversationState.TIMEOUT
            return 'æˆ‘ä»¬å·²ç»èŠäº†10è½®äº†ï¼Œæˆ‘æƒ³ç»“æŸè¿™ä¸ªå¯¹è¯ã€‚', False

        # ç”Ÿæˆç”¨æˆ·å“åº”
        user_response, should_continue = self._generate_user_response(agent_message)

        # æ›´æ–°å¯¹è¯çŠ¶æ€
        if not should_continue:
            self.current_state = ConversationState.SATISFIED

        self.conversation_history.append({
            'turn': self.turn_count,
            'user': user_response,
            'timestamp': time.time()
        })

        return user_response, should_continue

    def _generate_user_response(self, agent_message: str) -> Tuple[str, bool]:
        """ç”Ÿæˆç”¨æˆ·å“åº”çš„æ ¸å¿ƒé€»è¾‘"""

        prompt = self._build_response_prompt(agent_message)

        try:
            response = completion(
                model=self.model,
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7
            )

            result = json.loads(response.choices[0].message.content)
            user_response = result.get('response', 'æˆ‘ç†è§£äº†ã€‚')
            should_continue = result.get('continue', True)

            logger.info(f"ç”¨æˆ·å“åº”ç”Ÿæˆ - è½®æ¬¡: {self.turn_count}, ç»§ç»­: {should_continue}")

            return user_response, should_continue
        except Exception as e:
            logger.error(f"ç”Ÿæˆç”¨æˆ·å“åº”å¤±è´¥: {e}")
            return 'æˆ‘ç†è§£äº†ï¼Œè¯·ç»§ç»­ã€‚', True

    def _build_response_prompt(self, agent_message: str) -> str:
        """æ„å»ºç”Ÿæˆç”¨æˆ·å“åº”çš„æç¤ºè¯"""

        return f"""
ä½ æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿç”¨æˆ·ï¼Œæ­£åœ¨ä¸ä¸€ä¸ªææ–™è®¡ç®—AI agentè¿›è¡Œå¤šè½®å¯¹è¯ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆåˆé€‚çš„å“åº”ï¼š

å¯¹è¯ç›®æ ‡ï¼š
- åˆå§‹é—®é¢˜: {self.goal.initial_question}
- æœŸæœ›ç»“æœ: {', '.join(self.goal.expected_outcomes)}
- æˆåŠŸæ ‡å‡†: {', '.join(self.goal.success_criteria)}

å½“å‰çŠ¶æ€ï¼š
- å¯¹è¯è½®æ¬¡: {self.turn_count}/10

Agentæœ€æ–°å›å¤ï¼š
{agent_message}

è¯·åˆ†æagentçš„å›å¤æ˜¯å¦æ»¡è¶³ä»»åŠ¡éœ€æ±‚ï¼Œå¹¶ç”Ÿæˆåˆé€‚çš„å“åº”ã€‚

é‡è¦é™åˆ¶ï¼š
- å¯¹è¯æœ€å¤š10è½®ï¼Œå½“å‰æ˜¯ç¬¬{self.turn_count}è½®
- é™¤é¦–è½®å¯¹è¯å¤–ï¼Œå…¶ä»–è½®æ¬¡å°½å¯èƒ½ç®€çŸ­åœ°å›ç­”agentçš„é—®é¢˜ï¼Œå›å¤å†…å®¹ç´§æ‰£åˆå§‹é—®é¢˜ï¼Œç¦æ­¢å‘æ•£
- å¦‚æœagentåœ¨è¯¢é—®å…·ä½“å‚æ•°æˆ–è®¾ç½®ï¼Œæä¾›ç®€æ´æ˜ç¡®çš„å›ç­”
- å¦‚æœagentå·²ç»æä¾›äº†åˆå§‹ä»»åŠ¡æ‰€éœ€çš„ä¿¡æ¯æˆ–å®Œæˆäº†ä»»åŠ¡ï¼Œè¯·ç«‹åˆ»ç»“æŸå¯¹è¯
- ç¦æ­¢å›å¤å¯èƒ½å¯¼è‡´agentäº§ç”Ÿè¯¯è§£æˆ–åç¦»ç›®æ ‡çš„å†…å®¹

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "response": "ä½ çš„å›å¤å†…å®¹",
    "continue": true/false  // æ˜¯å¦ç»§ç»­å¯¹è¯
}}
"""

    def get_bohr_results(self, agent_message: str, job_id: List[str]) -> Tuple[str, bool]:
        """
        åŸºäºagentçš„å›å¤ç”Ÿæˆæ¨¡æ‹Ÿç”¨æˆ·çš„å“åº”

        Args:
            agent_message: agentçš„å›å¤å†…å®¹
            job_id: job_id

        Returns:
            Tuple[str, bool]: (ç”¨æˆ·å“åº”, æ˜¯å¦ç»§ç»­å¯¹è¯)
        """
        if not self.goal:
            raise ValueError('æœªè®¾ç½®å¯¹è¯ç›®æ ‡')

        self.turn_count += 1
        self.conversation_history.append({
            'turn': self.turn_count,
            'agent': agent_message,
            'timestamp': time.time()
        })

        # ç”Ÿæˆç”¨æˆ·å“åº”
        user_response = f'æŸ¥çœ‹idä¸º{job_id}çš„ä»»åŠ¡ç»“æœ'
        should_continue = True

        # æ›´æ–°å¯¹è¯çŠ¶æ€
        if not should_continue:
            self.current_state = ConversationState.SATISFIED

        self.conversation_history.append({
            'turn': self.turn_count,
            'user': user_response,
            'timestamp': time.time()
        })

        return user_response, should_continue

    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        return {
            'goal': self.goal.initial_question if self.goal else None,
            'total_turns': self.turn_count,
            'final_state': self.current_state.value,
            'duration_minutes': ((time.time() - self.start_time) / 60) if self.start_time else 0,
            'conversation_history': self.conversation_history
        }

    def get_last_user_response(self) -> str:
        """è·å–æœ€åçš„ç”¨æˆ·å“åº”"""
        if not self.conversation_history:
            return self.get_initial_question()

        # æŸ¥æ‰¾æœ€åä¸€ä¸ªç”¨æˆ·å“åº”
        for entry in reversed(self.conversation_history):
            if 'user' in entry:
                return entry['user']

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·å“åº”ï¼Œè¿”å›åˆå§‹é—®é¢˜
        return self.get_initial_question()


async def test_with_adk_agent(file_path):
    """ä¸ADK agentè¿›è¡Œå¤šè½®å¯¹è¯æµ‹è¯•"""
    print('=' * 80)
    print('ğŸ¤– ä¸ADK Agentå¤šè½®å¯¹è¯æµ‹è¯•')
    print('=' * 80)

    dataset_json = json.loads(load_dataset_json(file_path))
    eval_results = []
    for index, dataset_item in enumerate(dataset_json):
        time.sleep(10)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        session_service = InMemorySessionService()
        session = await session_service.create_session(
            app_name='matmaster_agent',
            user_id='human_simulator_test',
        )

        logger.info(f"Test Session: {session.id}")

        runner = Runner(
            app_name='matmaster_agent',
            agent=root_agent,
            session_service=session_service
        )

        # åˆ›å»ºäººç±»æ¨¡æ‹Ÿå™¨
        simulator = HumanSimulator()

        # æ•°æ®é¢„å¤„ç†
        scenario = {
            'name': dataset_item['initial_question'],
            'goal': ConversationGoal(
                initial_question=dataset_item['initial_question'],
                expected_outcomes=dataset_item['expected_outcomes'],
                success_criteria=dataset_item['success_criteria']
            )}

        print(f"\n{'=' * 20} æµ‹è¯•åœºæ™¯: {scenario['name']} {'=' * 20}")

        # è®¾ç½®å¯¹è¯ç›®æ ‡
        simulator.set_goal(scenario['goal'])
        initial_question = simulator.get_initial_question()

        print(f"ğŸ¯ å¯¹è¯ç›®æ ‡: {initial_question}")
        print(f"ğŸ“‹ æœŸæœ›ç»“æœ: {', '.join(scenario['goal'].expected_outcomes)}")
        print(f"âœ… æˆåŠŸæ ‡å‡†: {', '.join(scenario['goal'].success_criteria)}")

        # åˆå§‹åŒ–è®°å½•
        eval_results.append({})
        eval_results[index]['initial_question'] = initial_question
        eval_results[index]['expected_outcomes'] = scenario['goal'].expected_outcomes
        eval_results[index]['success_criteria'] = scenario['goal'].success_criteria
        for i in range(1, 6):
            eval_results[index][f'agent_response_{i}'] = ''
            eval_results[index][f'user_response_{i}'] = ''

        # å¼€å§‹å¯¹è¯
        conversation_ended = False
        turn_count = 0

        while not conversation_ended and turn_count < 10:
            turn_count += 1
            print(f"\nğŸ”„ ç¬¬ {turn_count} è½®å¯¹è¯:")

            # è·å–ç”¨æˆ·è¾“å…¥ï¼ˆä»æ¨¡æ‹Ÿå™¨ï¼‰
            if turn_count == 1:
                user_input = initial_question
            else:
                # ä»æ¨¡æ‹Ÿå™¨è·å–å“åº”
                user_input = simulator.get_last_user_response()

            print(f"ğŸ§‘ æ¨¡æ‹Ÿç”¨æˆ·: {user_input}")

            # è°ƒç”¨ADK agent
            try:
                content = types.Content(role='user', parts=[types.Part(text=user_input)])

                agent_response = ''

                events = runner.run_async(
                    user_id=session.user_id,
                    session_id=session.id,
                    new_message=content,
                    run_config=RunConfig(streaming_mode=StreamingMode.SSE)
                )

                # æ”¶é›†agentå“åº”
                async for event in events:
                    if event.content and event.content.parts:
                        for part in event.content.parts:
                            if part.text:
                                agent_response += part.text
            except asyncio.CancelledError:
                logger.error('ä»»åŠ¡è¢«å–æ¶ˆï¼Œå¯èƒ½æ˜¯è¶…æ—¶æˆ–ä½œç”¨åŸŸå–æ¶ˆå¯¼è‡´')
                print(f"âœ… å¯¹è¯åœ¨ç¬¬{turn_count}è½®ç»“æŸ")
                eval_results[index][f'agent_response_{turn_count}'] = 'ä»»åŠ¡è¢«å–æ¶ˆï¼Œå¯èƒ½æ˜¯è¶…æ—¶æˆ–ä½œç”¨åŸŸå–æ¶ˆå¯¼è‡´'
                break
            except Exception as e:
                logger.error(f"è·å–agentå“åº”å¤±è´¥: {e}")
                print(f"âœ… å¯¹è¯åœ¨ç¬¬{turn_count}è½®ç»“æŸ")
                eval_results[index][f'agent_response_{turn_count}'] = str(e)
                break

            eval_results[index][f'agent_response_{turn_count}'] = agent_response
            print(f"ğŸ¤– ADK Agent: {agent_response}")

            job_jsons = re.findall(r'<bohrium-chat-msg>(.*?)</bohrium-chat-msg>', agent_response)
            job_ids = []
            if job_jsons:
                for job_json in job_jsons:
                    try:
                        job_json = json.loads(job_json)
                        if 'eventData' in job_json and 'content' in job_json['eventData']:
                            content = job_json['eventData']['content']
                            if 'job_list' in content and 'job_id' in content['job_list']:
                                job_id = content['job_list']['job_id']
                                job_ids.append(job_id)
                    except Exception as e:
                        logger.error(f"æå–job_idå¤±è´¥: {e}")

            # æŸ¥è¯¢jobçŠ¶æ€
            if job_ids:
                job_ids = list(set(job_ids))
                while True:
                    time.sleep(10)
                    all_finished = True
                    for job_id in job_ids:
                        bohrium_client = Bohrium()
                        job_info = bohrium_client.job.detail(job_id)
                        logger.info(f"æŸ¥è¯¢åˆ°jobçŠ¶æ€: {job_id} - çŠ¶æ€: {job_info["status"]}")
                        if job_info['status'] not in [-1, 2]:
                            all_finished = False
                    if all_finished:
                        break

                # ä½¿ç”¨æ¨¡æ‹Ÿå™¨ç”Ÿæˆç”¨æˆ·å“åº”
                user_response, should_continue = simulator.get_bohr_results(agent_response, job_ids)
                eval_results[index][f'user_response_{turn_count}'] = user_response
                print(f"ğŸ§‘ æ¨¡æ‹Ÿç”¨æˆ·: {user_response}")
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿå™¨ç”Ÿæˆç”¨æˆ·å“åº”
                user_response, should_continue = simulator.generate_response(agent_response)
                eval_results[index][f'user_response_{turn_count}'] = user_response
                print(f"ğŸ§‘ æ¨¡æ‹Ÿç”¨æˆ·: {user_response}")

            if not should_continue:
                print(f"âœ… å¯¹è¯åœ¨ç¬¬{turn_count}è½®ç»“æŸ")
                break

        # è·å–å¯¹è¯æ‘˜è¦
        summary = simulator.get_conversation_summary()
        eval_results[index]['total_turns'] = summary['total_turns']
        eval_results[index]['final_state'] = summary['final_state']
        eval_results[index]['duration_minutes'] = summary['duration_minutes']
        print(f"\nğŸ“Š å¯¹è¯æ‘˜è¦:")
        print(f"   - æ€»è½®æ¬¡: {summary['total_turns']}")
        print(f"   - æœ€ç»ˆçŠ¶æ€: {summary['final_state']}")
        print(f"   - è€—æ—¶: {summary['duration_minutes']:.1f} åˆ†é’Ÿ")

        with open('evaluation_results.json', 'w') as f:
            json.dump(eval_results, f, indent=4, ensure_ascii=False)

        # ç®€å•çš„æˆåŠŸåˆ¤æ–­
        if summary['final_state'] == 'satisfied':
            print('âœ… æµ‹è¯•é€šè¿‡: å¯¹è¯æˆåŠŸå®Œæˆ')
        else:
            print('âŒ æµ‹è¯•å¤±è´¥: å¯¹è¯æœªæˆåŠŸå®Œæˆ')

        await runner.close()

    print('\n' + '=' * 80)
    print('ğŸ‰ å¤šè½®å¯¹è¯æµ‹è¯•å®Œæˆï¼')
    print('=' * 80)

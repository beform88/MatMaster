import logging
import os

from dotenv import load_dotenv
from google.adk.models.lite_llm import LiteLlm
from opik.integrations.adk import OpikTracer

from agents.matmaster_agent.constant import MATMASTER_AGENT_NAME

load_dotenv()
logger = logging.getLogger(__name__)

MODEL_MAPPING = {
    ('openai', 'gpt-4o-mini'): 'openai/gpt-4o-mini',
    ('openai', 'gpt-4o'): 'openai/gpt-4o',
    ('openai', 'o3-mini'): 'openai/o3-mini',
    ('openai', 'gemini2.5-pro'): 'openai/gemini-2.5-pro-preview-03-25',
    ('openai', 'gemini-2.5-pro-preview-05-06'): 'openai/gemini-2.5-pro-preview-05-06',
    ('openai', 'deepseek-r1'): 'openai/deepseek-r1',
    ('openai', 'claude-sonnet-4-20250514'): 'openai/claude-sonnet-4-20250514',
    (
        'openai',
        'gemini-2.5-flash-preview-05-20',
    ): 'openai/gemini-2.5-flash-preview-05-20',
    ('openai', 'qwen-plus'): 'openai/qwen-plus',
    ('openai', 'gpt-5'): 'openai/gpt-5',
    ('openai', 'gpt-5-nano'): 'openai/gpt-5-nano',
    ('openai', 'gpt-5-mini'): 'openai/gpt-5-mini',
    ('openai', 'gpt-5-chat'): 'openai/gpt-5-chat',
    ('azure', 'gpt-4o'): 'azure/gpt-4o',
    ('azure', 'gpt-4o-mini'): 'azure/gpt-4o-mini',
    ('litellm_proxy', 'gemini-2.0-flash'): 'litellm_proxy/gemini-2.0-flash',
    ('litellm_proxy', 'gemini-2.5-flash'): 'litellm_proxy/gemini-2.5-flash',
    ('litellm_proxy', 'gemini-2.5-pro'): 'litellm_proxy/gemini-2.5-pro',
    ('litellm_proxy', 'gemini-3-flash'): 'litellm_proxy/gemini-3-flash-preview',
    ('litellm_proxy', 'gemini-3-pro'): 'litellm_proxy/gemini-3-pro-preview',
    ('litellm_proxy', 'claude-sonnet-4'): 'litellm_proxy/claude-sonnet-4',
    ('litellm_proxy', 'gpt-5'): 'litellm_proxy/azure/gpt-5',
    ('litellm_proxy', 'gpt-5-mini'): 'litellm_proxy/azure/gpt-5-mini',
    ('litellm_proxy', 'gpt-5-nano'): 'litellm_proxy/azure/gpt-5-nano',
    ('litellm_proxy', 'gpt-5-chat'): 'litellm_proxy/azure/gpt-5-chat',
    ('litellm_proxy', 'zh-gpt-5-chat'): 'litellm_proxy/zh-gpt-5-chat',
    # ("gemini", "gemini1.5-turbo"): "gemini/gemini1.5-turbo",
    # ("gemini", "gemini2.5-pro"): "gemini/gemini-2.5-pro-preview-03-25",
    # ("deepseek", "deepseek-reasoner"): "deepseek/deepseek-reasoner",
    ('deepseek', 'deepseek-chat'): 'deepseek/deepseek-chat',
    ('volcengine', 'deepseek-chat'): 'volcengine/ep-20250210170324-dd9g4',
    ('volcengine', 'deepseek-R1-0528'): 'volcengine/ep-20250612143101-qf6n8',
    ('volcengine', 'deepseek-Seed-1.6'): 'volcengine/ep-20250627140204-clmmm',
    ('volcengine', 'Doubao-Seed-1.6-flash'): 'volcengine/ep-20250627141116-z2fv4',
    ('volcengine', 'Doubao-Seed-1.6-thinking'): 'volcengine/ep-20250627141021-h4wch',
}

DEFAULT_MODEL = os.getenv('DEFAULT_MODEL', 'litellm_proxy/azure/gpt-5-chat')
TOOL_SCHEMA_MODEL = os.getenv('TOOL_SCHEMA_MODEL', 'azure/gpt-4o')


class LLMConfig:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        azure_provider = 'azure'
        litellm_provider = 'litellm_proxy'
        deepseek_provider = 'deepseek'

        gpt_4o = 'gpt-4o'
        gpt_4o_mini = 'gpt-4o-mini'
        gemini_2_5_flash = 'gemini-2.5-flash'
        gemini_2_0_flash = 'gemini-2.0-flash'
        gemini_2_5_pro = 'gemini-2.5-pro'
        gemini_3_flash = 'gemini-3-flash'
        gemini_3_pro = 'gemini-3-pro'
        claude_sonnet_4 = 'claude-sonnet-4'
        deepseek_chat = 'deepseek-chat'
        gpt_5 = 'gpt-5'
        gpt_5_nano = 'gpt-5-nano'
        gpt_5_mini = 'gpt-5-mini'
        gpt_5_chat = 'gpt-5-chat'

        # Helper to init any provider model
        def _init_model(model: str):
            llm_kwargs = {}
            if model.endswith(gpt_5_chat) and 'litellm' in model:
                llm_kwargs = {'stream_options': {'include_usage': True}}
            logger.info(
                f'[{MATMASTER_AGENT_NAME}] model = {model}, llm_kwargs = {llm_kwargs}'
            )

            return LiteLlm(model=model, **llm_kwargs)

        # Gemini Models
        self.gemini_2_0_flash = _init_model(
            MODEL_MAPPING.get((litellm_provider, gemini_2_0_flash))
        )
        self.gemini_2_5_flash = _init_model(
            MODEL_MAPPING.get((litellm_provider, gemini_2_5_flash))
        )
        self.gemini_2_5_pro = _init_model(
            MODEL_MAPPING.get((litellm_provider, gemini_2_5_pro))
        )
        self.gemini_3_flash = _init_model(
            MODEL_MAPPING.get((litellm_provider, gemini_3_flash))
        )
        self.gemini_3_pro = _init_model(
            MODEL_MAPPING.get((litellm_provider, gemini_3_pro))
        )

        # Claude Models
        self.claude_sonnet_4 = _init_model(
            MODEL_MAPPING.get((litellm_provider, claude_sonnet_4))
        )

        # Deepseek Models
        self.deepseek_chat = _init_model(
            MODEL_MAPPING.get((deepseek_provider, deepseek_chat))
        )

        # GPT Models
        self.gpt_4o_mini = _init_model(MODEL_MAPPING.get((azure_provider, gpt_4o_mini)))
        self.gpt_4o = _init_model(MODEL_MAPPING.get((azure_provider, gpt_4o)))
        self.gpt_5 = _init_model(MODEL_MAPPING.get((litellm_provider, gpt_5)))
        self.gpt_5_nano = _init_model(MODEL_MAPPING.get((litellm_provider, gpt_5_nano)))
        self.gpt_5_mini = _init_model(MODEL_MAPPING.get((litellm_provider, gpt_5_mini)))
        self.gpt_5_chat = _init_model(MODEL_MAPPING.get((litellm_provider, gpt_5_chat)))

        # Default Model
        self.default_litellm_model = _init_model(DEFAULT_MODEL)
        self.tool_schema_model = _init_model(TOOL_SCHEMA_MODEL)

        # tracing
        self.opik_tracer = OpikTracer()

        self._initialized = True


def create_default_config() -> LLMConfig:
    return LLMConfig()


MatMasterLlmConfig = create_default_config()
